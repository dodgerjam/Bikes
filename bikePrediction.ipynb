{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2804e3475d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredstd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwls_prediction_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import timedelta, datetime \n",
    "\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_excel(\"TFLBikes.xls\", sheet_name=\"Data\")\n",
    "df[\"Day\"] = pd.to_datetime(df[\"Day\"])\n",
    "df = df[[\"Day\", \"Number of Bicycle Hires\"]]\n",
    "\n",
    "df_test = df.iloc[2500:]\n",
    "df = df.iloc[:2500]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets just do an initial plot to try and gain a preliminary understanding of how we are going to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(go.Scatter(\n",
    "    x = df['Day'],\n",
    "    y = df['Number of Bicycle Hires'],\n",
    "    text = df['Day'].dt.strftime('%Y-%m-%d'),\n",
    "    hovertemplate = '# of Bikes: %{y} <br>Date: %{text}<extra></extra>'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title = \"Number of TFL Bikes per day\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a cyclical trend annually, but also we imagine that on weekends we would observe more uses as people have more free time. So let's now investigate the cyclical trends on an annually and a weekly basis.\n",
    "\n",
    "First, we convert the day of the year to a value between 0 and 1 and then to an angle between 0 and 360 to plot with Plotly. We then plot this using a **polar plot**, allowing us to see the continuing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polar = df.groupby(df[\"Day\"].dt.dayofyear.apply(lambda x: 360*x/366)).mean()\n",
    "\n",
    "\n",
    "fig = go.Figure(data = [\n",
    "    go.Scatterpolar(\n",
    "        theta = df[\"Day\"].dt.dayofyear.apply(lambda x: 360*x/366),\n",
    "        r = df[\"Number of Bicycle Hires\"],\n",
    "        mode = 'markers',\n",
    "        marker = dict(size=1),\n",
    "        name = 'All Values',\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        theta = polar.index.values,\n",
    "        r = polar[\"Number of Bicycle Hires\"],\n",
    "        mode = 'lines',\n",
    "        name = 'Mean',\n",
    "    )])\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Repeated Yearly Trend\",\n",
    "    polar = dict(\n",
    "        angularaxis = dict(\n",
    "            ticktext = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "            tickvals = list(range(0,360, 30)),\n",
    "            tickmode=\"array\",\n",
    "            rotation = 0\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a pattern which may seem familiar if you remember your polar co-ordinates from a maths class you may have took. It looks similar to a graph of the form $r = 1 - cos(\\theta)$. Here's a little graph for you to play around with the values to convince yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step in np.arange(0, 2, 0.1):\n",
    "    fig.add_trace(\n",
    "        go.Scatterpolar(\n",
    "            visible=False,\n",
    "            name=\"ùúà = \" + str(step),\n",
    "            theta = np.array(range(360)),\n",
    "            r = [1 - step * np.cos(np.deg2rad(i)) for i in range(360)]\n",
    "        ))\n",
    "\n",
    "# Make 10th trace visible\n",
    "fig.data[10].visible = True\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "for i in range(len(fig.data)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": \"Slider switched to step: + {:.1f}\".format(np.arange(0, 2, 0.1)[i])}],  # layout attribute\n",
    "        label = \"{0:.1f}\".format(np.arange(0, 2, 0.1)[i])\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=10,\n",
    "    currentvalue={\"prefix\": \"r = 1 - \", \"suffix\": \" cos(theta)\"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    polar = dict(\n",
    "        radialaxis = dict(range=[0, 3])\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the cyclical weekly trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = df.groupby(df[\"Day\"].dt.dayofweek.apply(lambda x: 360*x/7)).mean()\n",
    "\n",
    "weekly = weekly.append(weekly.iloc[0])\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatterpolar(\n",
    "        r = weekly['Number of Bicycle Hires'],\n",
    "        theta = weekly.index,\n",
    "        mode = 'lines',\n",
    "        name = 'Average'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        theta = df[\"Day\"].dt.dayofweek.apply(lambda x: 360*x/7),\n",
    "        r = df[\"Number of Bicycle Hires\"],\n",
    "        mode = 'markers',\n",
    "        marker = dict(size=3),\n",
    "        name = 'All Values')\n",
    "    ])\n",
    "    \n",
    "fig.update_layout(\n",
    "    title = \"Repeated Weekly Trend\",\n",
    "    polar = dict(\n",
    "        angularaxis = dict(\n",
    "            ticktext = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun'],\n",
    "            tickvals = np.linspace(0,360,8)[:-1],\n",
    "            tickmode=\"array\",\n",
    "            rotation = 0)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar graph of what we saw for the cyclical annual graph except rotated slightly. To include this in our model we could apply a rotation by replacing the $\\cos(\\theta)$ term with a $\\cos(\\theta - \\alpha)$. However, will use the identity $\\cos(\\theta - \\alpha) = a \\cos(\\theta) + b \\sin(\\theta)$ to simplify)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning Modelling\n",
    "\n",
    "We have identified some strong features that could be used to model the daily usage of bikes that are:\n",
    "\n",
    "- $\\cos(\\frac{\\text{day of year}}{366})$\n",
    "- $\\cos(\\frac{\\text{day of week}}{7})$\n",
    "- $\\sin(\\frac{\\text{day of week}}{7})$\n",
    "\n",
    "First, let's see if the model works for the cyclic annual trend just using $\\cos(\\frac{\\text{day of year}}{366})$ and a bias term. We set up a simple linear regression with a bias term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PolarDay'] = df['Day'].dt.dayofyear.apply(lambda x: 360*x/366)\n",
    "\n",
    "A = np.array([[1, np.cos(i)] for i in df['PolarDay'].apply(lambda x: np.deg2rad(x)).values])\n",
    "\n",
    "b = df[['Number of Bicycle Hires']].values\n",
    "\n",
    "x = np.linalg.lstsq(A,b)[0]\n",
    "\n",
    "bhat = np.dot(A, x)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatterpolar(\n",
    "        theta = df[\"Day\"].dt.dayofyear.apply(lambda x: 360*x/366),\n",
    "        r = df[\"Number of Bicycle Hires\"],\n",
    "        mode = 'markers',\n",
    "        marker = dict(size=1),\n",
    "        name = 'All Values',\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        r = [b[0] for b in bhat],\n",
    "        theta = df['PolarDay'],\n",
    "        mode = 'lines',\n",
    "        name = 'Predicted'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        theta = polar.index.values,\n",
    "        r = polar[\"Number of Bicycle Hires\"],\n",
    "        mode = 'lines',\n",
    "        name = 'Mean',\n",
    "    )]\n",
    ")\n",
    "fig.update_layout(\n",
    "    title = \"Repeated Yearly Trend\",\n",
    "    polar = dict(\n",
    "        angularaxis = dict(\n",
    "            ticktext = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "            tickvals = list(range(0,360, 30)),\n",
    "            tickmode=\"array\",\n",
    "            rotation = 0\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the model performs okay, but is yet to compensate for the weekly fluctuations. So now let's try the weekly fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PolarWeekday'] = df['Day'].dt.dayofweek.apply(lambda x: 360*x/7)\n",
    "\n",
    "A = np.array([[1, np.cos(i), np.sin(i)] for i in df['PolarWeekday'].apply(lambda x: np.deg2rad(x)).values])\n",
    "\n",
    "b = df[['Number of Bicycle Hires']].values\n",
    "\n",
    "x = np.linalg.lstsq(A,b)[0]\n",
    "\n",
    "bhat = np.dot(A, x)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatterpolar(\n",
    "        r = df['Number of Bicycle Hires'],\n",
    "        theta = df['PolarWeekday'],\n",
    "        mode = 'markers',\n",
    "        name = 'actual'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        r = weekly.append(weekly.iloc[0])['Number of Bicycle Hires'],\n",
    "        theta = weekly.append(weekly.iloc[0]).index,\n",
    "        mode = 'lines',\n",
    "        name = 'Average'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        r = pd.DataFrame(bhat)[0],\n",
    "        theta = df['PolarWeekday'],\n",
    "        mode = 'lines',\n",
    "        name = 'predicted'\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Repeated Weekly Trend\",\n",
    "    polar = dict(\n",
    "        angularaxis = dict(\n",
    "            ticktext = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun'],\n",
    "            tickvals = np.linspace(0,360,8)[:-1],\n",
    "            tickmode=\"array\",\n",
    "            rotation = 0)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see this slightly more (1 additional term) model is able to cope with the variety of weekdays (roughly). I.e. Significantly lower on weekends than weekdays. Now let's combine the two models to see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "weekly = df.groupby(df[\"Day\"].dt.dayofweek.apply(lambda x: 360*x/7)).mean()\n",
    "\n",
    "A = np.array([[1, np.cos(i), np.sin(i)] for i in weekly.reset_index()['Day'].apply(lambda x: np.deg2rad(x)).values])\n",
    "\n",
    "b = weekly[['Number of Bicycle Hires']].values\n",
    "\n",
    "x = np.linalg.lstsq(A,b)[0]\n",
    "\n",
    "bhat = np.dot(A, x)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatterpolar(\n",
    "        r = weekly.append(weekly.iloc[0])['Number of Bicycle Hires'],\n",
    "        theta = weekly.append(weekly.iloc[0]),\n",
    "        mode = 'lines',\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        r = [x[0][0] + x[1][0]*np.cos(np.deg2rad(i)) + x[2][0]*np.sin(np.deg2rad(i)) for i in range(360)],\n",
    "        theta = list(range(360)),\n",
    "        mode = 'lines',\n",
    "        name = 'predicted'\n",
    "    )]\n",
    ")\n",
    "fig.update_layout(\n",
    "    title = \"Repeated Yearly Trend\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linRegModel(features, df_train, df_test = None, verbose = True):\n",
    "    \n",
    "    # Adding Polar Features\n",
    "    df_train = createPolarFeatures(df_train)\n",
    "\n",
    "    # Creating Feature Matrix\n",
    "    A = features(df_train)\n",
    "\n",
    "    # Creating Target Matrix\n",
    "    b = df_train[['Number of Bicycle Hires']].values\n",
    "\n",
    "    # Creating Model\n",
    "    model = sm.OLS(b, A)\n",
    "\n",
    "    # Fitting Model\n",
    "    results = model.fit()\n",
    "\n",
    "    # Printing Model Results\n",
    "    if verbose:\n",
    "        print(results.summary())\n",
    "\n",
    "    if df_test is None:\n",
    "\n",
    "        return insertResults(results, df_train, features)\n",
    "    \n",
    "    else:\n",
    "        df_test = createPolarFeatures(df_test)\n",
    "\n",
    "        A_test = features(df_test)\n",
    "\n",
    "        return insertResults(results, df_test, features)\n",
    "\n",
    "def simpleFeatures(df):\n",
    "\n",
    "    A = pd.concat([\n",
    "        df['PolarDay'].apply(np.deg2rad).apply(np.cos),\n",
    "        df['PolarWeekday'].apply(np.deg2rad).apply(np.cos),\n",
    "        df['PolarWeekday'].apply(np.deg2rad).apply(np.sin),\n",
    "        df['PolarDay'].apply(lambda x: 1),\n",
    "    ], axis=1).values\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def insertResults(results, df, features):\n",
    "\n",
    "    A = features(df)\n",
    "\n",
    "    # Calculating Upper and Lower Predictions\n",
    "    prstd, iv_l, iv_u = wls_prediction_std(results, exog = A,  alpha=0.05)\n",
    "\n",
    "    # Predicting the Model\n",
    "    df['Predicted'] = results.predict(exog = A)\n",
    "\n",
    "    # Calculating the Error for each entry\n",
    "    if 'Number of Bicycle Hires' in df.columns:\n",
    "        df['Error'] = df['Predicted'] - df['Number of Bicycle Hires']\n",
    "\n",
    "    # Inserting the CI\n",
    "    df['CI_Lower'] = iv_l\n",
    "    df['CI_Upper'] = iv_u\n",
    "\n",
    "    return df\n",
    "\n",
    "def createPolarFeatures(df):\n",
    "    df['PolarDay'] = df['Day'].dt.dayofyear.apply(lambda x: 360*x/366)\n",
    "    df['PolarWeekday'] = df['Day'].dt.dayofweek.apply(lambda x: 360*x/7)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = linRegModel(simpleFeatures, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an okay training RMSE, however let's see if we can do a little better by observing a global (non-cyclical) trend to the data. To do this, let's plot a rolling annual average to gain some sense of the data that is immune to any seasonal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [\n",
    "    go.Scatter(\n",
    "    x = df['Day'],\n",
    "    y = df['Number of Bicycle Hires'],\n",
    "    text = df['Day'].dt.strftime('%Y-%m-%d'),\n",
    "    hovertemplate = '# of Bikes: %{y} <br>Date: %{text}<extra></extra>',\n",
    "    name = 'All data'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "    x = df['Day'],\n",
    "    y = df['Number of Bicycle Hires'].rolling(365).mean(),\n",
    "    text = df['Day'].dt.strftime('%Y-%m-%d'),\n",
    "    hovertemplate = '# of Bikes: %{y} <br>Date: %{text}<extra></extra>',\n",
    "    name = 'Rolling Average (365 days)'\n",
    "    ),\n",
    "]\n",
    "    )\n",
    "fig.update_layout(\n",
    "    title = \"Number of TFL Bikes per day\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a general shallow increment over time. As we've focused on keeping this a simple linear model, let's just introduce a linear increasing term for each day and see how that does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearFeatures(df):\n",
    "\n",
    "    A = pd.concat([\n",
    "        df['PolarDay'].apply(np.deg2rad).apply(np.cos),\n",
    "        df['PolarWeekday'].apply(np.deg2rad).apply(np.cos),\n",
    "        df['PolarWeekday'].apply(np.deg2rad).apply(np.sin),\n",
    "        df['PolarDay'].apply(lambda x: 1),\n",
    "        pd.DataFrame(df.index.values, index = df.index)\n",
    "    ], axis=1).values\n",
    "\n",
    "    return A\n",
    "\n",
    "df = linRegModel(linearFeatures, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to decrease our RMSE by nearly 1000, which is an excellent result! Now let's plot the results with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linegraphFactory(df, true_vals = True, predicted = True, CI = True, suffix = \"\"):\n",
    "    \n",
    "    plots = []\n",
    "\n",
    "    if true_vals:\n",
    "        plots.append(go.Scatter(\n",
    "            x = df['Day'],\n",
    "            y = df['Number of Bicycle Hires'],\n",
    "            text = df['Day'].dt.strftime('%Y-%m-%d'),\n",
    "            hovertemplate = '# of Bikes: %{y} <br>Date: %{text}<extra></extra>',\n",
    "            line=dict(width=1, color = \"rgba(234,53,70)\"),\n",
    "            name = \"Actual\"+suffix\n",
    "            )\n",
    "        )\n",
    "         \n",
    "    if predicted:\n",
    "        plots.append(\n",
    "            go.Scatter(\n",
    "                x = df['Day'],\n",
    "                y = df['Predicted'],\n",
    "                text = df['Day'].dt.strftime('%Y-%m-%d'),\n",
    "                hovertemplate = '# of Bikes: %{y} <br>Date: %{text}<extra></extra>',\n",
    "                line=dict(width=1, color = \"rgba(248,102,36)\"),\n",
    "                name = \"Predicted\"+suffix,\n",
    "                )\n",
    "        )\n",
    "\n",
    "    if CI:\n",
    "        plots.append(go.Scatter(\n",
    "            x = pd.DataFrame(np.concatenate((df['Day'].values, df['Day'].values[::-1])))[0],\n",
    "            y = pd.concat((df['CI_Lower'], df['CI_Upper'].iloc[::-1])),\n",
    "            line=dict(width=1, dash='dash', color = \"rgba(249,200,14,0.5)\"),\n",
    "            mode = \"lines\",\n",
    "            name = \"CI\"+suffix,\n",
    "            fill = \"toself\",\n",
    "            fillcolor = \"rgba(249,200,14,0.5)\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return plots\n",
    "\n",
    "train_plots = linegraphFactory(df, suffix = \"train\")\n",
    "\n",
    "fig = go.Figure(data = train_plots\n",
    ")\n",
    "fig.update_layout(\n",
    "    title = \"TRAIN MSE = {:.5g} Bikes\".format(df['Error'].apply(lambda x: x**2).mean() ** 0.5)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the model is coping with the trends pretty well but let's investigating where it is failing (i.e the true value lies outside of the CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df['CI_Lower'] > df['Number of Bicycle Hires']\n",
    "cond2 = df['CI_Upper'] < df['Number of Bicycle Hires']\n",
    "\n",
    "print('Outliers per weekday')\n",
    "print(df[(cond1) | (cond2)]['Day'].dt.dayofweek.value_counts())\n",
    "\n",
    "print('Outliers per month')\n",
    "print(df[(cond1) | (cond2)]['Day'].dt.month.value_counts())\n",
    "\n",
    "print('Outliers per year')\n",
    "print(df[(cond1) | (cond2)]['Day'].dt.year.value_counts())\n",
    "\n",
    "print('Outliers per month-year')\n",
    "print(df[(cond1) | (cond2)]['Day'].apply(lambda x: \"{0}-{1}\".format(x.month, x.year)).value_counts().head(10))\n",
    "\n",
    "print('Outliers per weekday-month')\n",
    "print(df[(cond1) | (cond2)]['Day'].apply(lambda x: \"{0}-{1}\".format(x.dayofweek, x.month)).value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 32 of the occurances are from the beginning of the dataset (30 from 8-2010 and 2 from 7-2010). We will omit these from the dataset in the future. In fact, we will remove all dates before 2012 \n",
    "\n",
    "Saturdays and Sundays (combinging to 52 outliers) still proved much trickier for the model to predict - particularly in August (which had 23 outliers). So let's do some further investigation as to why this might be occuring - a preiliminary guess would be that during August and on weekends the usage is a lot more varied particularly as more hobbyists would use the bikes. This would mean that usage is probably more dependent on the weather etc - variables that we have neglected to consider.\n",
    "\n",
    "Let's explore the training data by using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Day'].dt.month_name()\n",
    "df['MonthNumber'] = df['Day'].dt.month\n",
    "\n",
    "N = 12 \n",
    "c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, N)]\n",
    "print(df.groupby('Month')['Number of Bicycle Hires'].std().sort_values(ascending=False))\n",
    "fig = px.box(df.sort_values(\"MonthNumber\"), x=\"Month\", y='Number of Bicycle Hires', color = \"Month\",color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the largest interquartile range of approximately 16k in August. This is reassuring as it indicates there isn't an underlying flaw in the model we've created causing it to predict during August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekday'] = df['Day'].dt.day_name() \n",
    "df['WeekdayNumber'] = df['Day'].dt.dayofweek\n",
    "\n",
    "\n",
    "N = 12 \n",
    "c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, N)]\n",
    "print(df.groupby('Weekday')['Number of Bicycle Hires'].std().sort_values(ascending=False))\n",
    "fig = px.box(df.sort_values('WeekdayNumber'), x=\"Weekday\", y='Number of Bicycle Hires', color = \"Weekday\",color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we see a larger variation over weekends, again indicating that weekends will be harder to predict.\n",
    "\n",
    "Let's also investigate areas where the model failed the most or the data is most anomalous. As this is real world data we can investigate it and try and find reasons for this anomalous behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = pd.concat([\n",
    "    df[['Day','Weekday', 'Number of Bicycle Hires', 'Predicted', 'Error']].sort_values('Error').head(5),\n",
    "    df.iloc[33:][['Day','Weekday', 'Number of Bicycle Hires', 'Predicted', 'Error']].sort_values('Error').tail(5),\n",
    "])\n",
    "outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the the top 5 Overshooting and Undershooting occurances in the model. It is quite fun that we can google what happened in London on these days - including Tube Strikes, the Olympics Speed Walking and some very sunny and rainy days (imagine that in a British Summer!) \n",
    "\n",
    "# Undershooting\n",
    "- 2015-07-09 - Tube Strike Action - https://www.itv.com/news/london/story/2015-07-09/strike-brings-londons-tube-network-to-a-standstill/\n",
    "- 2015-08-06 - Tube Strike Action - https://www.bbc.co.uk/news/live/uk-england-london-33674627\n",
    "- 2016-12-25 - Planned Strike Action/Christmas Day - https://en.wikipedia.org/wiki/London_Underground_strikes\n",
    "- 2017-01-09 - Strike Action -https://www.itv.com/news/london/2017-01-09/tube-strike-tfl-advise-passengers-to-complete-their-journey-by-6pm\n",
    "- 2017-04-09 - Really nice day - https://www.itv.com/news/2017-04-09/its-official-uk-enjoys-hottest-day-of-2017\n",
    "\n",
    "\n",
    "# Overshooting\n",
    "- 2014-08-25 - Rainy Bank Holiday Monday - https://metro.co.uk/2014/08/25/notting-hill-carnival-2014-the-rain-doesnt-dampen-the-crowd-on-bank-holiday-monday-4845458/\n",
    "- 2012-06-11 - Lots of roads shut off because of speed-walk in London 2012 Olympics - https://www.standard.co.uk/news/transport/800000-extra-train-seats-laid-on-for-penultimate-day-of-the-games-8034368.html\n",
    "- 2012-04-09 - Bank Holiday\n",
    "- 2011-06-12 - Possibly just extremely rainy - particularly for June\n",
    "- 2011-06-05 - Again possibly extremely rainy\n",
    "\n",
    "Okay so lets remove these points from the data as well as the earlier data and retrain our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removing = np.concatenate([\n",
    "                outliers.index.values,\n",
    "                df[df['Day'].dt.year <= 2011].index.values\n",
    "                ])\n",
    "\n",
    "df_drop = linRegModel(linearFeatures, df.drop(removing), verbose = False)\n",
    "\n",
    "train_drop_plots = linegraphFactory(df_drop)\n",
    "\n",
    "fig = go.Figure(data = train_drop_plots\n",
    ")\n",
    "fig.update_layout(\n",
    "    title = \"TRAIN MSE = {:.5g} Bikes\".format(df_drop['Error'].apply(lambda x: x**2).mean() ** 0.5)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the train MSE has gone down, but hopefully this technique also helps reduce andy overfitting effects on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = linRegModel(linearFeatures, df_drop, df_test = df_test, verbose = False)\n",
    "\n",
    "test_plots = linegraphFactory(df_test, suffix = \"_test\")\n",
    "\n",
    "fig = go.Figure(data = train_drop_plots+ test_plots\n",
    ")\n",
    "fig.update_layout(shapes=[\n",
    "    dict(\n",
    "      type= 'line',\n",
    "      yref= 'paper', y0= 0, y1= 1,\n",
    "      xref= 'x', x0= df_test['Day'].min(), x1= df_test['Day'].min(),\n",
    "      line = {'color': 'black','width': 1, 'dash': 'dot',}\n",
    "    )],\n",
    "    title = \"TEST MSE = {:.5g} Bikes\".format(df_test['Error'].apply(lambda x: x**2).mean() ** 0.5))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[df_test['Day'].min()],\n",
    "    y=[3_000],\n",
    "    mode=\"text\",\n",
    "    text=[f\"{df_test['Day'].min().date()} \"],\n",
    "    textposition='middle left',\n",
    "    name = \"\"\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test MSE is a little higher than our training result, but it appears sensible and is quite close so this is quite a promising result. However, even better than that - as our model independent or previous results (like an LSTM wouldn't be) - our error doesn't seem to increase as time continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data = go.Scatter(\n",
    "        x = df_test['Day'],\n",
    "        y = pd.concat([df, df_test])['Error'].rolling(365).mean().iloc[-len(df_test):],\n",
    "        mode = 'lines'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title = 'Test Rolling Average (365 Days) Error')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to wrap things up, let's try and predict to the present day even if we can't evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df = pd.DataFrame(\n",
    "            pd.Series([df_test['Day'].max() + timedelta(days=i) for i in range((datetime.today() - df_test['Day'].max()).days)], \n",
    "            name = \"Day\")\n",
    "            )\n",
    "\n",
    "future_df.index += df_test.index.max() + 1\n",
    "\n",
    "future_df = linRegModel(linearFeatures, df_drop, df_test = future_df, verbose = False)\n",
    "\n",
    "future_plots = linegraphFactory(future_df, true_vals=False, suffix = \"_future\")\n",
    "\n",
    "fig = go.Figure(data = train_drop_plots+ test_plots + future_plots\n",
    ")\n",
    "fig.update_layout(shapes=[\n",
    "    dict(\n",
    "      type= 'line',\n",
    "      yref= 'paper', y0= 0, y1= 1,\n",
    "      xref= 'x', x0= df_test['Day'].min(), x1= df_test['Day'].min(),\n",
    "      line = {'color': 'black','width': 1, 'dash': 'dot',}\n",
    "    ),\n",
    "    dict(\n",
    "      type= 'line',\n",
    "      yref= 'paper', y0= 0, y1= 1,\n",
    "      xref= 'x', x0= future_df['Day'].min(), x1= future_df['Day'].min(),\n",
    "      line = {'color': 'black','width': 1, 'dash': 'dot',}\n",
    "    ),\n",
    "\n",
    "])\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[df_test['Day'].min(), future_df['Day'].min()],\n",
    "    y=[3_000, 3_000],\n",
    "    mode=\"text\",\n",
    "    text=[f\"{df_test['Day'].min().date()} \", f\"{future_df['Day'].min().date()} \"],\n",
    "    textposition='middle left',\n",
    "    name = \"\"\n",
    "))\n",
    "\n",
    "fig.update_layout(title = 'Prediction to the Present Day')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other bonues of this method is we have an entirely linear model - which makes it very interpretable. So say for example, you were working on a data science project at TFL and had to report to the stakeholders about how your model predicted the number of bikes used per day. In this scenario you could present them an easy to notate mathematical equation that would be simple to understand (or at least simpler than a black box model like a neural net).\n",
    "\n",
    "I hoped you enjoyed reading this notebook, and if you have any comments please let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
